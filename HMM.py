#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 14 20:07:46 2020

@author: veax-void
N - number of latent (hidden) states 
M - number of observables
pi - initial state probability distribution
O - observations
A - transition matrix
B - emission matrix
"""
import numpy as np
import pandas as pd
from itertools import product

class ProbabilityVector:
	def __init__(self, probabilities: dict):
		states = probabilities.keys()
		probs = list(probabilities.values())
		assert len(states) == len(probs), \
			"The probabilities must match the states."
		assert len(states) == len(set(states)), \
			"The states must be unique."
		assert abs(np.sum(probs) - 1.0) < 1e-12, \
			"Probabilities must sum up to 1."
		assert len(list(filter(lambda x: 0 <= x <= 1+1e-12, probs))) == len(probs), \
			"Probabilities must be numbers from [0, 1] interval."
		
		self.states = sorted(probabilities)
		self.values = np.array(list(map(lambda x: 
			probabilities[x], self.states))).reshape(1, -1)
		
	@classmethod
	def initialize(cls, states: list):
		size = len(states)
		rand = np.random.rand(size) / (size**2) + 1 / size
		rand /= rand.sum(axis=0)
		return cls(dict(zip(states, rand)))
	
	@classmethod
	def from_numpy(cls, array: np.ndarray, states: list):
		return cls(dict(zip(states, list(array))))

	@property
	def dict(self):
		return {k:v for k, v in zip(self.states, list(self.values.flatten()))}

	@property
	def df(self):
		return pd.DataFrame(self.values, columns=self.states, index=['probability'])

	def __repr__(self):
		return "P({}) = {}.".format(self.states, self.values)

	def __eq__(self, other):
		if not isinstance(other, ProbabilityVector):
			raise NotImplementedError
		if (self.states == other.states) and (self.values == other.values).all():
			return True
		return False

	def __getitem__(self, state: str) -> float:
		if state not in self.states:
			raise ValueError("Requesting unknown probability state from vector.")
		index = self.states.index(state)
		return float(self.values[0, index])

	def __mul__(self, other) -> np.ndarray:
		if isinstance(other, ProbabilityVector):
			return self.values * other.values
		elif isinstance(other, (int, float)):
			return self.values * other
		else:
			NotImplementedError

	def __rmul__(self, other) -> np.ndarray:
		return self.__mul__(other)

	def __matmul__(self, other) -> np.ndarray:
		if isinstance(other, ProbabilityMatrix):
			return self.values @ other.values

	def __truediv__(self, number) -> np.ndarray:
		if not isinstance(number, (int, float)):
			raise NotImplementedError
		x = self.values
		return x / number if number != 0 else x / (number + 1e-12)

	def argmax(self):
		index = self.values.argmax()
		return self.states[index]

class ProbabilityMatrix:
	def __init__(self, prob_vec_dict: dict):
		
		assert len(prob_vec_dict) > 1, \
			"The numebr of input probability vector must be greater than one."
		assert len(set([str(x.states) for x in prob_vec_dict.values()])) == 1, \
			"All internal states of all the vectors must be indentical."
		assert len(prob_vec_dict.keys()) == len(set(prob_vec_dict.keys())), \
			"All observables must be unique."

		self.states	  = sorted(prob_vec_dict)
		self.observables = prob_vec_dict[self.states[0]].states
		self.values	  = np.stack([prob_vec_dict[x].values for x in self.states]).squeeze() 

	@classmethod
	def initialize(cls, states: list, observables: list):
		size = len(states)
		rand = np.random.rand(size, len(observables)) / (size**2) + 1 / size
		rand /= rand.sum(axis=1).reshape(-1, 1)
		aggr = [dict(zip(observables, rand[i, :])) for i in range(len(states))]
		pvec = [ProbabilityVector(x) for x in aggr]
		return cls(dict(zip(states, pvec)))

	@classmethod
	def from_numpy(cls, array: np.ndarray, states: list, observables: list):
		p_vecs = [ProbabilityVector(dict(zip(observables, x))) for x in array]
		return cls(dict(zip(states, p_vecs)))

	@property
	def dict(self):
		return self.df.to_dict()

	@property
	def df(self):
		return pd.DataFrame(self.values, columns=self.observables, index=self.states)

	def __repr__(self):
		return "PM {} states: {} -> obs: {}.".format(
			self.values.shape, self.states, self.observables)

	def __getitem__(self, observable: str) -> np.ndarray:
		if observable not in self.observables:
			raise ValueError("Requesting unknown probability observable from the matrix.")
		index = self.observables.index(observable)
		return self.values[:, index].reshape(-1, 1)

class HiddenMarkovChain:
	def __init__(self, T, E, pi):
		self.T = T  # transmission matrix A
		self.E = E  # emission matrix B
		self.pi = pi
		self.states = pi.states
		self.observables = E.observables
	
	def __repr__(self):
		return "HML states: {} -> observables: {}.".format(
			len(self.states), len(self.observables))
	
	@classmethod
	def initialize(cls, states: list, observables: list):
		T = ProbabilityMatrix.initialize(states, states)
		E = ProbabilityMatrix.initialize(states, observables)
		pi = ProbabilityVector.initialize(states)
		return cls(T, E, pi)

	def uncover(self, observations: list) -> list:
		alphas = self._alphas(observations)
		betas = self._betas(observations)
		maxargs = (alphas * betas).argmax(axis=1)
		return list(map(lambda x: self.states[x], maxargs))

	def score(self, observations: list) -> float:
		alphas = self._alphas(observations)
		return float(alphas[-1].sum())
	
	def run(self, length: int) -> (list, list):
		assert length >= 0, "The chain needs to be a non-negative number."
		s_history = [0] * (length + 1)
		o_history = [0] * (length + 1)
		
		prb = self.pi.values
		obs = prb @ self.E.values
		s_history[0] = np.random.choice(self.states, p=prb.flatten())
		o_history[0] = np.random.choice(self.observables, p=obs.flatten())
		
		for t in range(1, length + 1):
			prb = prb @ self.T.values
			obs = prb @ self.E.values
			s_history[t] = np.random.choice(self.states, p=prb.flatten())
			o_history[t] = np.random.choice(self.observables, p=obs.flatten())
		
		return o_history, s_history
	
	def _create_all_chains(self, chain_length):
		return list(product(*(self.states,) * chain_length))
	
	def _alphas(self, observations: list) -> np.ndarray:
		alphas = np.zeros((len(observations), len(self.states)))
		#print('hmm', self.pi.values, self.E)
		alphas[0, :] = self.pi.values * self.E[observations[0]].T
		for t in range(1, len(observations)):
			alphas[t, :] = (alphas[t - 1, :].reshape(1, -1) @ self.T.values) \
						 * self.E[observations[t]].T
		return alphas
	
	def _betas(self, observations: list) -> np.ndarray:
		betas = np.zeros((len(observations), len(self.states)))
		betas[-1, :] = 1
		for t in range(len(observations) - 2, -1, -1):
			betas[t, :] = (self.T.values @ (self.E[observations[t + 1]] \
						* betas[t + 1, :].reshape(-1, 1))).reshape(1, -1)
		return betas
	
	def _digammas(self, observations: list) -> np.ndarray:
		L, N = len(observations), len(self.states)
		digammas = np.zeros((L - 1, N, N))

		alphas = self._alphas(observations)
		betas = self._betas(observations)
		score = self.score(observations)
		for t in range(L - 1):
			P1 = (alphas[t, :].reshape(-1, 1) * self.T.values)
			P2 = self.E[observations[t + 1]].T * betas[t + 1].reshape(1, -1)
			digammas[t, :, :] = P1 * P2 / score
		return digammas 

class HiddenMarkovModel:
	def __init__(self, hmc: HiddenMarkovChain):
		self.layer = hmc
		self._score_init = 0
		self.score_history = []

	@classmethod
	def initialize(cls, states: list, observables: list):
		layer = HiddenMarkovChain.initialize(states, observables)
		return cls(layer)

	def update(self, observations: list) -> float:
		alpha = self.layer._alphas(observations)
		beta = self.layer._betas(observations)
		digamma = self.layer._digammas(observations)
		score = alpha[-1].sum()
		gamma = alpha * beta / score 

		L = len(alpha)
		obs_idx = [self.layer.observables.index(x) for x in observations]
		capture = np.zeros((L, len(self.layer.states), len(self.layer.observables)))
		for t in range(L):
			capture[t, :, obs_idx[t]] = 1.0

		pi = gamma[0]
		T = digamma.sum(axis=0) / gamma[:-1].sum(axis=0).reshape(-1, 1)
		E = (capture * gamma[:, :, np.newaxis]).sum(axis=0) / gamma.sum(axis=0).reshape(-1, 1)

		self.layer.pi = ProbabilityVector.from_numpy(pi, self.layer.states)
		self.layer.T = ProbabilityMatrix.from_numpy(T, self.layer.states, self.layer.states)
		self.layer.E = ProbabilityMatrix.from_numpy(E, self.layer.states, self.layer.observables)
			
		return score

	def train(self, observations: list, epochs: int, tol=None):
		self._score_init = 0
		self.score_history = (epochs + 1) * [0]
		early_stopping = isinstance(tol, (int, float))
		
		for epoch in range(1, epochs + 1):
			score = self.update(observations)
			print("Training... epoch = {} out of {}, score = {}.".format(epoch, epochs, score))
			if early_stopping and abs(self._score_init - score) / score < tol:
				print("Early stopping.")
				break
			self._score_init = score
			self.score_history[epoch] = score
		
class HMM:
	def __init__(self, states, observables):
		# Initialize HiddenMarkovModel
		hmc = HiddenMarkovChain.initialize(states, observables)
		self.model = HiddenMarkovModel(hmc)

	def fit(self, observations, epochs, tolerance=None):
		self.model.train(observations, epochs, tolerance)
	
	def score(self, observations):
		return self.model.layer.score(observations)

	def generate(self, length):
		chain = self.model.layer.run(length)[0]
		return chain
	
	def get_A(self):
		return self.model.layer.T.df.to_numpy().copy()
	def get_B(self):
		return self.model.layer.E.df.to_numpy().copy()
	def get_pi(self):
		return self.model.layer.pi.df.to_numpy()[0].copy()
	
	def set_A(self, A):
		self.model.layer.T = ProbabilityMatrix.from_numpy(A,
				  self.model.layer.T.states, self.model.layer.T.observables)
		
	def set_B(self, B):
		self.model.layer.E = ProbabilityMatrix.from_numpy(B, 
				  self.model.layer.E.states, self.model.layer.E.observables)
		
	def set_pi(self, pi):
		self.model.layer.pi = ProbabilityVector.from_numpy(pi,
				  self.model.layer.pi.states)
	
